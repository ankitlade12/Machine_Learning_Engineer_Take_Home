{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574377ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from keras.models import load_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c819d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data (replace 'data.csv' with your dataset)\n",
    "data = pd.read_csv('data_daily.csv')\n",
    "data['# Date'] = pd.to_datetime(data['# Date'])\n",
    "data.set_index('# Date', inplace=True)\n",
    "data = data.resample('D').sum()  # Ensure daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6144971",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3cdb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73729653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "data['Receipt_Count'] = scaler.fit_transform(data['Receipt_Count'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971befbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i+sequence_length])\n",
    "        y.append(data[i+sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 12  # You can adjust this to control the sequence length (e.g., 12 months)\n",
    "X, y = create_sequences(data['Receipt_Count'], sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a05d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(data))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea1095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(sequence_length, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813238e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccce91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the initial sequence for prediction\n",
    "last_sequence = data['Receipt_Count'][-sequence_length:].values\n",
    "predictions = []\n",
    "\n",
    "for _ in range(sequence_length):\n",
    "    input_data = last_sequence.reshape(1, sequence_length, 1)\n",
    "    prediction = model.predict(input_data)\n",
    "    predictions.append(prediction[0, 0])\n",
    "    last_sequence = np.append(last_sequence[1:], prediction[0, 0])\n",
    "\n",
    "# Inverse transform the predictions to get the original scale\n",
    "predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1773c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Generate a sequence of dates for 2022\n",
    "start_date = pd.to_datetime('2022-01-01')\n",
    "end_date = pd.to_datetime('2022-12-31')\n",
    "forecast_dates = pd.date_range(start_date, end_date, freq='M')\n",
    "\n",
    "# Create the figure and plot the data\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(data.index, data['Receipt_Count'], label='Historical Data')\n",
    "plt.plot(forecast_dates, predictions, label='Predictions', color='red')\n",
    "plt.title('Scanned Receipts Forecast for 2022')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Receipts')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a0c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final1.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adad4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e257cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('final.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_sequence = data['Receipt_Count'][-sequence_length:].values\n",
    "predictions = []\n",
    "\n",
    "for month in range(12):\n",
    "    a = last_sequence.reshape(1, sequence_length, 1)\n",
    "    prediction = model.predict(a)\n",
    "    print(prediction.shape)\n",
    "    predictions.append(prediction[0, 0])\n",
    "    last_sequence = np.append(last_sequence[1:], prediction[0, 0])\n",
    "\n",
    "# Inverse transform the predictions to get the original scale\n",
    "predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06152729",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = data['# Date'].iloc[-1]\n",
    "last_date\n",
    "#date_range = [last_date + timedelta(days=i) for i in range(1, sequence_length + 13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b051e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Step 1: Data Preparation\n",
    "# Load or create a DataFrame named 'data' with 'date' and 'receipts' columns for 2021.\n",
    "# Ensure that 'date' is in datetime format.\n",
    "data = pd.read_csv('data_daily.csv')\n",
    "data['# Date'] = pd.to_datetime(data['# Date'])\n",
    "data.set_index('# Date', inplace=True)\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "# data['# Date'] = pd.to_datetime(data['# Date'])\n",
    "# data.set_index('# Date', inplace=True)\n",
    "data = data.resample('D').sum()  # Ensure daily data\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "data['Receipt_Count'] = scaler.fit_transform(data[['Receipt_Count']])\n",
    "\n",
    "# Create input sequences and target values\n",
    "look_back = 30  # Number of days to look back for prediction\n",
    "X, y = [], []\n",
    "for i in range(len(data) - look_back):\n",
    "    X.append(data.iloc[i:i + look_back, 0].values)\n",
    "    y.append(data.iloc[i + look_back, 0])\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Split data into training and testing\n",
    "train_size = int(len(X) * 0.8)\n",
    "trainX, testX = X[:train_size], X[train_size:]\n",
    "trainY, testY = y[:train_size], y[train_size:]\n",
    "\n",
    "# Step 3: Create and Train the LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=5, batch_size=1, verbose=2)\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "testPredict = model.predict(testX)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform(testY.reshape(-1, 1))\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3719660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Monthly Receipt Prediction for 2022\n",
    "# To predict monthly values for 2022, forecast each day and aggregate the results.\n",
    "# Use the trained model to predict one day ahead, and repeat for each day in 2022.\n",
    "# Then aggregate the results for each month.\n",
    "\n",
    "# Initialize an array to store monthly predictions for 2022\n",
    "monthly_predictions_2022 = []\n",
    "\n",
    "# Generate initial input data for the first day of 2022\n",
    "input_data = testX[-look_back:].reshape(1, look_back, 1)\n",
    "print(input_data.shape)\n",
    "\n",
    "\n",
    "# Define the number of days in each month in 2022\n",
    "days_in_months_2022 = {\n",
    "    1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30,\n",
    "    7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12: 31\n",
    "}\n",
    "\n",
    "# Iterate through each month in 2022\n",
    "for month in range(1, 13):\n",
    "    monthly_receipt_predictions = []\n",
    "\n",
    "    # Predict each day of the current month\n",
    "    for day in range(days_in_months_2022[month]):\n",
    "        # Predict the next day's receipts\n",
    "        predicted_receipts = model.predict(input_data)\n",
    "        monthly_receipt_predictions.append(predicted_receipts[0, 0])\n",
    "\n",
    "        # Update the input data for the next day's prediction\n",
    "        input_data = np.append(input_data[:, 1:, :], predicted_receipts.reshape(1, 1, 1), axis=1)\n",
    "\n",
    "    # Aggregate daily predictions for the current month\n",
    "    monthly_predictions_2022.append(sum(monthly_receipt_predictions))\n",
    "\n",
    "# Display the monthly predictions for 2022\n",
    "for month, prediction in enumerate(monthly_predictions_2022, start=1):\n",
    "    print(f\"Month {month}: {prediction:.2f} scanned receipts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3bb71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae28e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "import pandas as pd\n",
    "\n",
    "# Load historical sales data\n",
    "data = pd.read_csv('data_daily.csv')  # Replace with your data source\n",
    "data['# Date'] = pd.to_datetime(data['# Date'])\n",
    "data.set_index('# Date', inplace=True)\n",
    "data = data.resample('D').sum()  # Ensure daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7742c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "data['Receipt_Count'] = scaler.fit_transform(data[['Receipt_Count']])\n",
    "\n",
    "# Create input sequences and target values\n",
    "look_back = 12  # Number of days to look back for prediction\n",
    "X, y = [], []\n",
    "for i in range(len(data) - look_back):\n",
    "    X.append(data.iloc[i:i + look_back, 0].values)\n",
    "    y.append(data.iloc[i + look_back, 0])\n",
    "X, y = np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7531267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "trainX, testX = X[:train_size], X[train_size:]\n",
    "trainY, testY = y[:train_size], y[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db473e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY, epochs=50, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dd6d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(testX)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform(testY.reshape(-1, 1))\n",
    "\n",
    "# Evaluate the model (you can use various metrics)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(testY, testPredict)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55323407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the initial sequence for prediction\n",
    "last_sequence = data['Receipt_Count'][-sequence_length:].values\n",
    "predictions = []\n",
    "\n",
    "for _ in range(sequence_length):\n",
    "    input_data = last_sequence.reshape(1, sequence_length, 1)\n",
    "    prediction = model.predict(input_data)\n",
    "    predictions.append(prediction[0, 0])\n",
    "    last_sequence = np.append(last_sequence[1:], prediction[0, 0])\n",
    "\n",
    "# Inverse transform the predictions to get the original scale\n",
    "predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an array to store monthly predictions for 2023\n",
    "monthly_predictions_2023 = []\n",
    "\n",
    "# Generate initial input data for the first day of 2023\n",
    "a = data['Receipt_Count'][-look_back:].values \n",
    "input_data = a.reshape(1, look_back, 1)\n",
    "print(a)\n",
    "# Define the number of days in each month in 2023\n",
    "days_in_months_2023 = {\n",
    "    1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30,\n",
    "    7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12: 31\n",
    "}\n",
    "\n",
    "# Iterate through each month in 2023\n",
    "for month in range(1, 13):\n",
    "    monthly_sales_predictions = []\n",
    "\n",
    "    # Predict each day of the current month\n",
    "    for day in range(days_in_months_2023[month]):\n",
    "        # Predict the next day's sales\n",
    "        predicted_sales = model.predict(input_data)\n",
    "        monthly_sales_predictions.append(predicted_sales[0, 0])\n",
    "\n",
    "        # Update the input data for the next day's prediction\n",
    "        input_data = np.append(input_data[:, 1:, :], predicted_sales.reshape(1, 1, 1), axis=1)\n",
    "\n",
    "    # Aggregate daily predictions for the current month\n",
    "    monthly_predictions_2023.append(sum(monthly_sales_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51171ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f4169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafaa18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your daily data for 2021 (replace 'your_data.csv' with your data source)\n",
    "data = pd.read_csv('data_daily.csv')\n",
    "\n",
    "# Create a feature for the month from the date\n",
    "data['# Date'] = pd.to_datetime(data['# Date'])\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "\n",
    "# Aggregate data by month\n",
    "monthly_data = data.groupby('Month')['Receipt_Count'].sum().reset_index()\n",
    "print(monthly_data)\n",
    "\n",
    "# Extract features and target\n",
    "X = monthly_data[['Year','Month']].values.reshape(-1, 1)\n",
    "y = monthly_data['Receipt_Count'].values.reshape(-1, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler_X = MinMaxScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "# Scale the target\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = scaler_y.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(1,)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '12' with the month number you want to predict\n",
    "future_month = np.array([[3]])\n",
    "\n",
    "# Scale the future month using the same scaler used for X\n",
    "scaled_future_month = scaler_X.transform(future_month)\n",
    "\n",
    "# Make the prediction\n",
    "scaled_prediction = model.predict(scaled_future_month)\n",
    "\n",
    "# Inverse transform the prediction to get the actual number of receipts\n",
    "predicted_receipts = scaler_y.inverse_transform(scaled_prediction)\n",
    "\n",
    "print(f'Predicted number of receipts for December 2022: {predicted_receipts[0, 0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a9757",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_months = np.arange(1, 13).reshape(-1, 1)  # Predict for each month\n",
    "scaled_future_months = scaler_X.transform(future_months)\n",
    "scaled_predictions = model.predict(scaled_future_months)\n",
    "predicted_receipts = scaler_y.inverse_transform(scaled_predictions).flatten()\n",
    "\n",
    "# Create a graph combining historical and predicted data\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot historical data\n",
    "plt.plot(monthly_data['Month'], monthly_data['Receipt_Count'], marker='o', linestyle='-', color='b', label='Historical Data')\n",
    "\n",
    "# Plot predicted data for 2022\n",
    "plt.plot(np.arange(1, 13), predicted_receipts, marker='o', linestyle='--', color='r', label='Predicted Data (2022)')\n",
    "\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Receipts')\n",
    "plt.title('Historical and Predicted Receipts for 2021 and 2022')\n",
    "plt.xticks(np.arange(1, 13))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff45cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa64e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load and preprocess your data\n",
    "data = pd.read_csv('data_daily.csv')  # Replace 'receipts_data.csv' with your data file.\n",
    "data['# Date'] = pd.to_datetime(data['# Date'])\n",
    "data.set_index('# Date', inplace=True)\n",
    "\n",
    "# Resample the data on a monthly basis\n",
    "monthly_data = data['Receipt_Count'].resample('D').sum()\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(monthly_data.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe36e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 12  # You can adjust this based on your data and requirements.\n",
    "X_train, y_train = create_sequences(normalized_data, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0627ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = int(0.8 * len(data))\n",
    "# X_train, X_test = X[:train_size], X[train_size:]\n",
    "# y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba40e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, activation='relu', input_shape=(seq_length, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21b9346d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                10400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10451 (40.82 KB)\n",
      "Trainable params: 10451 (40.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b93b443d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input data to be non-empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1319\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_dataset_and_inferred_steps(\n\u001b[0;32m   1315\u001b[0m     strategy, x, steps_per_epoch, class_weight, distribute\n\u001b[0;32m   1316\u001b[0m )\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected input data to be non-empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input data to be non-empty."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25488984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the simulated 2022 data\n",
    "simulated_data_2022 = list(normalized_data[-seq_length:])\n",
    "\n",
    "# Create a function to generate monthly predictions\n",
    "def generate_monthly_predictions(model, current_seq):\n",
    "    predicted_value = model.predict(current_seq)\n",
    "    return predicted_value[0][0]\n",
    "\n",
    "# Loop over each month in 2022\n",
    "for _ in range(12):\n",
    "    # Create the current sequence for prediction\n",
    "    current_seq = np.array([simulated_data_2022[-seq_length:]]).reshape(1, seq_length, 1)\n",
    "    \n",
    "    # Generate the prediction for the month\n",
    "    predicted_value = generate_monthly_predictions(model, current_seq)\n",
    "    \n",
    "    # Append the predicted value to the simulated data\n",
    "    simulated_data_2022.append(predicted_value)\n",
    "\n",
    "# Inverse transform the simulated data to the original scale\n",
    "simulated_data_2022 = scaler.inverse_transform(np.array(simulated_data_2022).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_data_2022 = list(normalized_data[-seq_length:])\n",
    "simulated_data_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408af6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
